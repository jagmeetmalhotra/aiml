{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WEEK 1 INTRO TO PYTHON - NUMPY and PANDAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Key Libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few Mathematical Expressions using numpy\n",
    "\n",
    "\n",
    "*  Check out this link for Numpy mathermatical functions\n",
    "\n",
    "https://docs.scipy.org/doc/numpy-1.13.0/reference/routines.math.html#trigonometric-functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Numpy functions invoked by using prefix np.function like np.sin() or np.sqrt() etc\n",
    "#\n",
    "# sin(90) or sin(pi/2)\n",
    "# tan (60) or tan(pi/3)\n",
    "# arccos(-1) in degrees using formula\n",
    "# arcsin(-1) in degress using rad2deg\n",
    "# cos (60) using deg2rad\n",
    "# log(e^pi)\n",
    "# log10(0.001)\n",
    "# sqrt(3.0)\n",
    "# floor of the division of 2 real numbers\n",
    "# remainder of the division of 2 numbers\n",
    "#\n",
    "# Let's execute above expressions in python with numpy functions\n",
    "#\n",
    "print(np.sin(np.pi/2))\n",
    "print(np.tan(np.pi/3))\n",
    "print((180/np.pi)*np.arccos(-1))\n",
    "print(np.rad2deg(np.arcsin(-1)))\n",
    "print(np.cos(np.deg2rad(60.)))\n",
    "print(np.log(np.exp(np.pi)))\n",
    "print(np.sqrt(3.0))\n",
    "print(np.floor_divide(13.,3.))\n",
    "print(np.mod(14,3))\n",
    "print(np.log10(10**5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of Arrays from lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# 1-D row matrix/array\n",
    "vec=np.array([1,2,3,4,5])\n",
    "print('1D row array\\n',vec)\n",
    "#\n",
    "#print a 2D 3x3 array and its transpose\n",
    "mat=np.array([[1,0,2],[0,1,3],[4,0,1]])\n",
    "print('\\n2D 3x3 array\\n',mat)\n",
    "\n",
    "print('\\nTranspose of above matrix\\n',mat.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using functions arange, linspace, zeros and ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "print('\\033[1m'+\"Note the Rules of Range and Linspace\"+'\\033[0m\\n')\n",
    "print('Print consecutive integers starting with 0 and <10')\n",
    "print(np.arange(0,10),'\\n')\n",
    "print('Print an A.P beginning with 3 with a difference of 6 and < 24')\n",
    "print(np.arange(3,24,6))\n",
    "print('\\nBreakup 0-10 range into 21 equidistant numbers inclusive of 0 and 10')\n",
    "print(np.linspace(0,10,21))\n",
    "print('\\nReshaped array into 6x4 matrix\\n',(np.linspace(0,23,24)).reshape(6,4))\n",
    "print('\\n3x2 zeroes\\n',np.zeros([3,2]))\n",
    "print('\\n3x5 ones\\n',np.ones([3,5]))\n",
    "print('\\033[1m'+ '\\n6x6 IDENTITY MATRIX' +'\\033[0m')\n",
    "print(np.eye(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locating entries and changing values in numpy vectors/ arrays\n",
    "\n",
    "* Using Random Number generator\n",
    "\n",
    "* Reshaping arrays\n",
    "\n",
    "* Retrieving elements and changing the values of an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "print(np.random.randint(2,52),'\\n')\n",
    "#\n",
    "# Generate a random vector of size 24 based on a standard normal distribution\n",
    "rand_vec=np.random.randn(24)\n",
    "print(rand_vec,'\\n')\n",
    "print(rand_vec.size, '\\n')\n",
    "print(rand_vec[9], '\\n')\n",
    "print(rand_vec[18:21],'\\n')\n",
    "print(\"\\nVector elements where Index is from range of numbers\\n\")\n",
    "print(rand_vec[np.arange(0,15,3)])\n",
    "#\n",
    "# Reshape into 2D array\n",
    "#\n",
    "rand_mat=rand_vec.reshape(4,6)\n",
    "print('')\n",
    "print(rand_mat,'\\n')\n",
    "print(rand_mat.shape)\n",
    "print('')\n",
    "print(rand_mat.size)\n",
    "print('')\n",
    "print(\"1st 2 rows, 4th and 5th column data\")\n",
    "print(rand_mat[0:2,3:5])\n",
    "print('')\n",
    "print(\"Replacing all 2nd column values to zero\")\n",
    "rand_mat[:,1]=0.0\n",
    "print(rand_mat)\n",
    "print('')\n",
    "print(\"Replacing 3rd row values to 0to5\")\n",
    "rand_mat[2,:]=np.arange(0,6)\n",
    "print(rand_mat)\n",
    "#\n",
    "# Be careful with defining sub-matrices and assigning new values to the sub-matrix elements\n",
    "# we could alter the original matrix from which the sub-matrix is defined if we don't use copy()\n",
    "#\n",
    "sub_mat=rand_mat[0:3,0:3].copy()\n",
    "sub_mat[:]=23\n",
    "print('')\n",
    "print(sub_mat)\n",
    "print('')\n",
    "print(rand_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing logicals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "rand_vec1=np.random.randn(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (rand_vec1)\n",
    "print('')\n",
    "print(rand_vec1>0)\n",
    "print('')\n",
    "print(rand_vec1[rand_vec1>0])\n",
    "print('')\n",
    "print(rand_vec1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rand_mat)\n",
    "print('')\n",
    "print(\"Transforms matrix to vector\")\n",
    "print(rand_mat[rand_mat>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rand_vec1)\n",
    "rand_vec1[rand_vec1>0.5]= -1.\n",
    "print('')\n",
    "print(rand_vec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_vec2=np.random.randn(16)\n",
    "rand_vec2=rand_vec2.reshape(4,4)\n",
    "print(rand_vec2)\n",
    "print('')\n",
    "eye4=np.eye(4)+1\n",
    "print(eye4)\n",
    "print('')\n",
    "print('dot product of two above matrices')\n",
    "print(np.dot(rand_vec2,eye4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Load Numpy objects into Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the array data into filename\n",
    "# Single array = np.save\n",
    "# multiple arrays = np.savez\n",
    "np.save('rand_vec_data',rand_vec)\n",
    "np.savez('arrays_exercise1',rand_vecf=rand_vec,rand_vec1f=rand_vec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_vec=np.load('rand_vec_data.npy')\n",
    "print(loaded_vec)\n",
    "print('')\n",
    "loaded_zip=np.load('arrays_exercise1.npz')\n",
    "print(loaded_zip)\n",
    "print('')\n",
    "print(loaded_zip['rand_vecf'])\n",
    "print('')\n",
    "print(loaded_zip['rand_vec1f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load files as text files\n",
    "#\n",
    "np.savetxt('text_file_rand_mat.txt',rand_mat,delimiter=',')\n",
    "rand_mat_txt=np.loadtxt('text_file_rand_mat.txt',delimiter=',')\n",
    "print(rand_mat)\n",
    "print('')\n",
    "print(rand_mat_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions lambda\n",
    "sum_3=lambda x,y,z:x+y+z\n",
    "sum_3(1,3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same function defined with name\n",
    "def sum_4(a,b,c,d):\n",
    "    x=a+b+c+d\n",
    "    return(x)\n",
    "#\n",
    "sum_4(2,4,5,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 1: Pandas - Series and Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a series from a list then rename indices and create dataframe from lists/arrays\n",
    "#\n",
    "mylist=[1.,4.5,5.6,-2.4,3.,6.7]\n",
    "myarray=np.array(mylist)\n",
    "#\n",
    "myseries1=pd.Series(data=mylist)\n",
    "print(myseries1)\n",
    "print('')\n",
    "myseries2=pd.Series(data=myarray)\n",
    "print(myseries2)\n",
    "print('')\n",
    "print(myseries1[4])\n",
    "print('')\n",
    "mylabels=['first','second','third','fourth','fifth','sixth']\n",
    "myseries3=pd.Series(data=mylist,index=mylabels)\n",
    "print(myseries3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myseries4=pd.Series([1.,2.5,3.4,-1.6],['first', 'second', 'third','fourth'])\n",
    "print(myseries4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.concat([myseries3,myseries4],axis=1,sort=False)\n",
    "print(df1)\n",
    "df2=pd.DataFrame(np.random.randn(5,5))\n",
    "print('')\n",
    "print(df2)\n",
    "print('')\n",
    "df3=pd.concat([myseries4,myseries3],axis=0,sort=True)\n",
    "print('')\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=pd.DataFrame(np.random.randn(4,4),index=['row-1','row-2','row-3','row-4'],columns=['col-1','col-2','col-3','col-4'])\n",
    "print('')\n",
    "print(df4)\n",
    "print('')\n",
    "print(df4[['col-1','col-3']])\n",
    "print('')\n",
    "print(df4.loc['row-2'])\n",
    "print('')\n",
    "print('2nd row')\n",
    "print(df4.iloc[1])\n",
    "print('')\n",
    "print('3rd row')\n",
    "print(df4.iloc[2,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.loc[['row-4','row-2'],['col-4','col-1']]\n",
    "df4.loc['row-2']\n",
    "df4.iloc[:2,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df4[df4>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['col-5']=np.random.randn(4,1)\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.drop('col-1',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.drop('row-3',axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['new name']=['This','is','the','row']\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.set_index('new name',inplace=True)\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={'prodID':['101','102','103','104','104'], \n",
    "      'prodname':['X','Y','Z','X','W'],\n",
    "                  'profit':['2738','2727','3497','7347','3743']}\n",
    "dataframe=pd.DataFrame(data)\n",
    "dataframe\n",
    "grouped_data=dataframe.groupby('prodID')\n",
    "grouped_data.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating, Merging and Joining DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "df7 = pd.DataFrame({\"customer\":['101','102','103','104'], \n",
    "                    'category': ['cat2','cat2','cat1','cat3'],\n",
    "                    'important': ['yes','no','yes','yes'],\n",
    "                    'sales': [123,52,214,663]},index=[0,1,2,3])\n",
    "\n",
    "df8 = pd.DataFrame({\"customer\":['101','103','104','105'], \n",
    "                    'color': ['yellow','green','green','blue'],\n",
    "                    'distance': [12,9,44,21],\n",
    "                    'sales': [123,214,663,331]},index=[4,5,6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df7,df8],axis=0,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df7,df8],axis=0,sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df7,df8],axis=1,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df7,df8,how='outer',on='customer') # outer merge is union of on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df7,df8,how='inner',on='customer') # inner merge is intersection of on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df7,df8,how='left',on='customer') # left merge is just first on, but all columns ... left is just first df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df7,df8,how='right',on='customer') # right merge is just first on, but all columns ... right is second df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9 = pd.DataFrame({'Q1': [101,102,103],\n",
    "                    'Q2': [201,202,203]},\n",
    "                   index=['I0','I1','I2'])\n",
    "\n",
    "df10 = pd.DataFrame({'Q3': [301,302,303],\n",
    "                    'Q4': [401,402,403]},\n",
    "                   index=['I0','I2','I3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join behaves just like merge, \n",
    "# except instead of using the values of one of the columns \n",
    "# to combine data frames, it uses the index labels\n",
    "df9.join(df10,how='outer') # outer, inner, left, and right work the same as merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9.join(df10,how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8['color'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8['color'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=df8[(df8['customer']!='105')&(df8['color']!='green')]\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df8['sales'].mean())\n",
    "print(df8['distance'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profit(s):\n",
    "    return s*0.5 # 50% markup..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8['sales'].apply(profit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8['color'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11 = df8[['distance','sales']]\n",
    "df11.applymap(profit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_sum(co):\n",
    "    return sum(co)\n",
    "df11.apply(col_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11.applymap(col_sum)\n",
    "# This is wrong since applymap is for global elements of dframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df8['color']\n",
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8.sort_values(by='distance',inplace=True)\n",
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if some series has multiple of the same value then we can group all the unique entries together\n",
    "mydict = {'customer': ['Customer 1','Customer 1','Customer2','Customer2','Customer3','Customer3'], \n",
    "          'product1': [1.1,2.1,3.8,4.2,5.5,6.9],\n",
    "          'product2': [8.2,9.1,11.1,5.2,44.66,983]}\n",
    "df6 = pd.DataFrame(mydict,index=['Purchase 1','Purchase 2','Purchase 3','Purchase 4','Purchase 5','Purchase 6'])\n",
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = df6.groupby('customer')\n",
    "print(grouped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar to numpy arrays, we can also save and load dataframes to csv files, and also Excel files\n",
    "\n",
    "df8.to_csv('df8.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df8 = pd.read_csv('df8.csv',index_col=0)\n",
    "new_df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8.to_excel('df8.xlsx',index=False,sheet_name='first sheet')\n",
    "newer_df8 = pd.read_excel('df8.xlsx',sheet_name='first sheet',index_col=0)\n",
    "newer_df8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASE STUDY ONLINE GAMES\n",
    "\n",
    "* Data has various online boardgames and metadata associated with it to analyze\n",
    "* There's game attributes and user feedback as part of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df=pd.read_csv('games.csv')\n",
    "print(\"Shape of games_df: \",games_df.shape, \"Size of games_df: \", games_df.size, '\\n')\n",
    "# Print the 1st 5 rows of the dataframe\n",
    "games_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info on dataframe in terms of datatype and # of records(rows)\n",
    "games_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the games by yearpublished in ascending sequence\n",
    "games_df.sort_values(by='yearpublished',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(games_df.yearpublished,'\\n')\n",
    "X=np.array(games_df.yearpublished);\n",
    "print('\\n',X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the game(s) with max playing time amongst all games\n",
    "print(games_df['playingtime'].max(),'\\n')\n",
    "games_df[games_df['playingtime']==games_df['playingtime'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the mean playing time for all games put together\n",
    "games_df['playingtime'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the games with max and min total comments\n",
    "games_df[games_df['total_comments']==games_df['total_comments'].max()]\n",
    "games_df[games_df['total_comments']==games_df['total_comments'].min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What game has id 1500\n",
    "games_df[games_df['id']==1500]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the average minage and bayes_average_rating of all games per game \"type\"? (boardgame & boardgameexpansion)\n",
    "games_df.groupby('type').mean()['minage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df.groupby('type').mean()['bayes_average_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many boardgames and boardgameexpansions are there in the dataset?\n",
    "games_df['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is there a correlation between playing time and total comments for the games? - Use the .corr() function \n",
    "games_df[['playingtime','total_comments']].corr() \n",
    "# No correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the distance plot for average rating for each game\n",
    "sns.displot(games_df['average_rating'], kde='True');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare type of game and playingtime using  a stripplot\n",
    "sns.stripplot(x=games_df['type'], y=games_df['playingtime'], jitter= True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CASE STUDY-  WEEKLY TRACKER  FOR TIME & DATE OBJECTS\n",
    "\n",
    "* The data is a weekly tracker of activity of a working manager by a daily   \n",
    "  scheduler / tracker app \n",
    "* We will try and read the timestamp and convert to analyzable time data\n",
    "* We will look at the activity specific metrics in terms of weekly timespent\n",
    "* Basic Exploratory Data Analysis (non-visual) is first used to study the data \n",
    "  and glean useful information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get the Data \n",
    "df = pd.read_csv('Weekly_schedule_tracker.csv')\n",
    "\n",
    "#View the first 5 rows of data\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'START_TIME'] = df['START_TIME'].apply(lambda x: pd.datetime.strptime(x, '%m/%d/%Y %H:%M'))\n",
    "df.loc[:, 'END_TIME'] = df['END_TIME'].apply(lambda x: pd.datetime.strptime(x, '%m/%d/%Y %H:%M'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the duration for the rides\n",
    "df['DIFF'] = (df['END_TIME'] - df['START_TIME'])/60.\n",
    "print(df['DIFF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert duration to numbers(minutes)\n",
    "df.loc[:, 'DIFF'] = df['DIFF'].apply(lambda x: pd.Timedelta.to_pytimedelta(x).days/(24*60) +pd.Timedelta.to_pytimedelta(x).seconds/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DIFF'].head()\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DIFF'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Capture Hour, Day, Month and Year of Schedule in a separate column\n",
    "df['month'] = pd.to_datetime(df['START_TIME']).dt.month\n",
    "df['Year'] = pd.to_datetime(df['START_TIME']).dt.year\n",
    "df['Day'] = pd.to_datetime(df['START_TIME']).dt.day\n",
    "df['Hour'] = pd.to_datetime(df['START_TIME']).dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Capture day of week and rename to weekday names\n",
    "df['day_of_week'] = pd.to_datetime(df['START_TIME']).dt.dayofweek\n",
    "days = {0:'Mon',1:'Tue',2:'Wed',3:'Thur',4:'Fri',5:'Sat',6:'Sun'}\n",
    "\n",
    "df['day_of_week'] = df['day_of_week'].apply(lambda x: days[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename the numbers in the Month column to calendar months\n",
    "import calendar\n",
    "df['month'] = df['month'].apply(lambda x: calendar.month_abbr[x])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CATEGORY in hrs')\n",
    "df.groupby(['CATEGORY']).sum()['DIFF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DIFF'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.groupby(['CATEGORY']).sum()['DIFF'])*100./df['DIFF'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEEK 2 INTRO TO PYTHON - PLOTTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns   # Why sns?  It's a reference to The West Wing\n",
    "import matplotlib.pyplot as plt  # seaborn is based on matplotlib\n",
    "sns.set(color_codes=True) # adds a nice background to the graphs\n",
    "%matplotlib inline \n",
    "# tells python to actually display the graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Automotive dataset\n",
    "auto = pd.read_csv('Automobile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto['make'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.groupby('make')['price'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto['curb_weight'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto['curb_weight'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto['body_style'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto[(auto['make']=='toyota')&(auto['body_style']=='hatchback')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto[auto['horsepower']>150].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto[(auto['body_style']=='sedan') & (auto['price']<7000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto[auto['price']>40000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting with seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate plots\n",
    "sns.histplot(auto['highway_mpg'], kde='True');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(auto['normalized_losses']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can turn the kde off and put a tic mark along the x-axis for every data point with rug\n",
    "sns.displot(x=auto['city_mpg'], kde=False, rug=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bivariate plot\n",
    "sns.scatterplot(x=auto['engine_size'],y=auto['horsepower'],color='blue');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"engine_size\",y=\"horsepower\",data=auto);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bivariate plot with hue representing density of data within the 'hex zone' - darker = denser\n",
    "sns.jointplot(x=auto['engine_size'], y=auto['horsepower'],kind='hex',color='brown');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=auto['engine_size'], y=auto['horsepower'], kind=\"kde\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing pairplots with multiple pairs\n",
    "sns.pairplot(auto[['normalized_losses', 'engine_size', 'horsepower']]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot(x=auto['fuel_type'], y=auto['horsepower'], jitter=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spreads out the overlaid data records (eg: multiple vehicles with same hp)\n",
    "sns.swarmplot(x='fuel_type',y='horsepower', data=auto, size=4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=auto['number_of_doors'], y=auto['horsepower'])\n",
    "#n as whiskers below for each box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot with avg hp boxtop and line representing 95% confidence interval\n",
    "sns.barplot(x=auto['body_style'], y=auto['horsepower'], hue=auto['fuel_type']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto[auto['body_style']=='convertible']['horsepower'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto[auto['body_style']=='convertible']['horsepower'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(auto['body_style'],hue=auto['fuel_type']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# point plot with avg hps with 95% confidence interval vs body_style (category)\n",
    "sns.pointplot(auto['body_style'], auto['horsepower'], hue=auto['number_of_doors'],linestyles='');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple catergorical box plots considering 1x (catergory- fuel type), 1y (variate - hp) and 1 hue (# of doors)\n",
    "sns.catplot(x=\"fuel_type\",\n",
    "               y = \"horsepower\",\n",
    "               hue=\"number_of_doors\", \n",
    "               col=\"drive_wheels\", \n",
    "               data=auto, \n",
    "               kind=\"box\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple count plots for different types of 'col' column data\n",
    "sns.catplot(x=\"fuel_type\",\n",
    "               hue=\"number_of_doors\", \n",
    "               col=\"drive_wheels\", \n",
    "               data=auto, \n",
    "               kind=\"count\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(y=\"horsepower\", x=\"engine_size\", data=auto);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate linear trends for fuel type (gas and diesel)\n",
    "sns.lmplot(y=\"horsepower\", x=\"engine_size\",hue=\"fuel_type\", data=auto);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some plots from games_df - Average rating histogram\n",
    "sns.distplot(games_df['average_rating']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bivariate plot to understand correlation\n",
    "sns.jointplot(games_df['minage'], games_df['average_rating']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression - trend between 'x' and 'y' datasets\n",
    "sns.regplot(x=\"playingtime\", y=\"average_rating\", data=games_df[games_df['playingtime'] < 500]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF WORKSHOP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
