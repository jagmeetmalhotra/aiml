{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"03 cnn optimized","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"_BZy-xRjwpQM"},"source":["# Download the datasets and unzip"]},{"cell_type":"markdown","metadata":{"id":"sYNNI6n2nAwS"},"source":["Download the kaggle dataset of cats and dogs images"]},{"cell_type":"code","metadata":{"id":"a4moUdic5RAx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624507375452,"user_tz":-330,"elapsed":11669,"user":{"displayName":"Vibhav Kharangate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTxso7WxORgT2TMx-Jc5_pXjshGzLeb1R1aVGgHrU=s64","userId":"06804277127361149800"}},"outputId":"09b2943e-3440-4f66-fbad-45bfa33a998f"},"source":["!wget https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n","!unzip -q kagglecatsanddogs_3367a.zip \n","print ('dataset downloaded')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["--2021-06-24 04:02:42--  https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n","Resolving download.microsoft.com (download.microsoft.com)... 23.215.184.109, 2600:1408:9000:887::e59, 2600:1408:9000:89d::e59\n","Connecting to download.microsoft.com (download.microsoft.com)|23.215.184.109|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 824894548 (787M) [application/octet-stream]\n","Saving to: ‘kagglecatsanddogs_3367a.zip’\n","\n","kagglecatsanddogs_3 100%[===================>] 786.68M   187MB/s    in 4.3s    \n","\n","2021-06-24 04:02:46 (184 MB/s) - ‘kagglecatsanddogs_3367a.zip’ saved [824894548/824894548]\n","\n","dataset downloaded\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MNmn45TeyE3A"},"source":["# Create training data"]},{"cell_type":"code","metadata":{"id":"a7Mw8W6Vn9F2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624507377281,"user_tz":-330,"elapsed":1837,"user":{"displayName":"Vibhav Kharangate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTxso7WxORgT2TMx-Jc5_pXjshGzLeb1R1aVGgHrU=s64","userId":"06804277127361149800"}},"outputId":"ba28d5da-0c5d-43da-f2c5-8fd370cbf81b"},"source":["#import all libraries\n","import os, random, cv2, numpy\n","print('import done')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["import done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CFEEjxUtoTOu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624507379376,"user_tz":-330,"elapsed":11,"user":{"displayName":"Vibhav Kharangate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTxso7WxORgT2TMx-Jc5_pXjshGzLeb1R1aVGgHrU=s64","userId":"06804277127361149800"}},"outputId":"bb1913f6-56f5-4b54-960c-c8b0cfef67c9"},"source":["categories=['Dog','Cat'] #folder and category names\n","training_data=[] # empty list that we'll use to store the final data set\n","img_size=70\n","print('variables initialized')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["variables initialized\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9vARvigZq-ZW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624507405791,"user_tz":-330,"elapsed":26423,"user":{"displayName":"Vibhav Kharangate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTxso7WxORgT2TMx-Jc5_pXjshGzLeb1R1aVGgHrU=s64","userId":"06804277127361149800"}},"outputId":"a0799355-1e70-4666-d097-7a2eaddd36df"},"source":["print('downsizing dogs and cats')\n","for i in range(len(categories)):\n","  print('category is',categories[i] )\n","  \n","  for img in os.listdir(f'PetImages/{categories[i]}'): #iterate through images in a particular folder\n","    #using try except to escape the corrupt images\n","    try:\n","        im_array=cv2.imread(f'PetImages/{categories[i]}/{img}',cv2.IMREAD_GRAYSCALE) # load the image in memory and load it as a grayscale(1 channel)\n","        new_array= cv2.resize(im_array,(img_size,img_size)) #downsize the image to 70x70 size\n","    except:\n","        print(f'{img} was skipped')\n","\n","    training_data.append([new_array, i]) #add the processed image and label to the dataset\n","\n","#shuffle the dataset to avoid having dogs and cats separately\n","random.shuffle(training_data)\n","print(\"database import complete\")\n","print (f'{len(training_data)} images added')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["downsizing dogs and cats\n","category is Dog\n","7969.jpg was skipped\n","7459.jpg was skipped\n","2688.jpg was skipped\n","2877.jpg was skipped\n","11853.jpg was skipped\n","6238.jpg was skipped\n","10158.jpg was skipped\n","10797.jpg was skipped\n","11675.jpg was skipped\n","1866.jpg was skipped\n","2384.jpg was skipped\n","10401.jpg was skipped\n","7369.jpg was skipped\n","10747.jpg was skipped\n","8730.jpg was skipped\n","5604.jpg was skipped\n","4367.jpg was skipped\n","3136.jpg was skipped\n","1308.jpg was skipped\n","6059.jpg was skipped\n","Thumbs.db was skipped\n","5736.jpg was skipped\n","11702.jpg was skipped\n","11410.jpg was skipped\n","6718.jpg was skipped\n","3288.jpg was skipped\n","9188.jpg was skipped\n","7112.jpg was skipped\n","11849.jpg was skipped\n","3588.jpg was skipped\n","7133.jpg was skipped\n","category is Cat\n","5553.jpg was skipped\n","9565.jpg was skipped\n","3491.jpg was skipped\n","7968.jpg was skipped\n","660.jpg was skipped\n","9171.jpg was skipped\n","10404.jpg was skipped\n","3300.jpg was skipped\n","4833.jpg was skipped\n","140.jpg was skipped\n","7978.jpg was skipped\n","Thumbs.db was skipped\n","11210.jpg was skipped\n","9778.jpg was skipped\n","8470.jpg was skipped\n","850.jpg was skipped\n","10820.jpg was skipped\n","10501.jpg was skipped\n","2663.jpg was skipped\n","11874.jpg was skipped\n","11565.jpg was skipped\n","10125.jpg was skipped\n","936.jpg was skipped\n","11935.jpg was skipped\n","666.jpg was skipped\n","database import complete\n","25002 images added\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UpMYTExlViJL","executionInfo":{"status":"ok","timestamp":1624507405793,"user_tz":-330,"elapsed":19,"user":{"displayName":"Vibhav Kharangate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTxso7WxORgT2TMx-Jc5_pXjshGzLeb1R1aVGgHrU=s64","userId":"06804277127361149800"}},"outputId":"88dec5d6-24af-403d-9e56-4d2ee2c8dce5"},"source":["print(training_data[1])"],"execution_count":5,"outputs":[{"output_type":"stream","text":["[array([[249, 249, 131, ..., 255, 254, 249],\n","       [250, 250, 137, ..., 254, 255, 251],\n","       [252, 250, 126, ..., 157, 154, 154],\n","       ...,\n","       [ 95,  90,  50, ..., 118, 141, 114],\n","       [ 87,  71,  56, ..., 100, 111, 108],\n","       [110,  68,  74, ..., 125, 101, 113]], dtype=uint8), 0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5s2nTBMYMntv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624507408389,"user_tz":-330,"elapsed":36,"user":{"displayName":"Vibhav Kharangate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTxso7WxORgT2TMx-Jc5_pXjshGzLeb1R1aVGgHrU=s64","userId":"06804277127361149800"}},"outputId":"9c1874b6-b4c5-4586-bdcf-c83ab82ef328"},"source":["#separate images and labels\n","x,y=[],[]\n","\n","for features,label in training_data:\n","    x.append(features)\n","    y.append(label)\n","    \n","print('x and y datasets created')\n","\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["x and y datasets created\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NgQ43qOMMJkH","executionInfo":{"status":"ok","timestamp":1624507552325,"user_tz":-330,"elapsed":652,"user":{"displayName":"Vibhav Kharangate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTxso7WxORgT2TMx-Jc5_pXjshGzLeb1R1aVGgHrU=s64","userId":"06804277127361149800"}},"outputId":"8d884aaa-b20c-43f7-b846-b3caeeea2d96"},"source":["numpy.array(x).shape"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(25002, 70, 70)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"xsuooUWaL4BE"},"source":["#cnn model will require an imput of 4 dimensions in the form of a numpy array\n","x=numpy.array(x)\n","print(x)\n","x=x.reshape(-1,img_size,img_size,1)\n","x=x/255 #normalize\n","y=numpy.array(y)\n","print('dataset shuffled and normalized')\n","print(x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v8kf6zozymv0"},"source":["# Train the model"]},{"cell_type":"code","metadata":{"id":"rbsjJNXlzb0A","executionInfo":{"status":"ok","timestamp":1624459202634,"user_tz":-330,"elapsed":1729,"user":{"displayName":"Vibhav Kharangate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTxso7WxORgT2TMx-Jc5_pXjshGzLeb1R1aVGgHrU=s64","userId":"06804277127361149800"}}},"source":["#import libraries\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"-_H9gkjYP30l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624459257565,"user_tz":-330,"elapsed":54938,"user":{"displayName":"Vibhav Kharangate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTxso7WxORgT2TMx-Jc5_pXjshGzLeb1R1aVGgHrU=s64","userId":"06804277127361149800"}},"outputId":"bdd67c49-5cdd-4a82-c89d-7bbe58882893"},"source":["model= Sequential()\n","\n","#1st layer should always have input shape\n","# create a conv layer with 64 nodes and 3x3 window size\n","# convolution does not do any machine learning it only extracts the features \n","model.add(Conv2D(64,(3,3), input_shape=x.shape[1:], activation='relu'))\n","model.add(MaxPooling2D(pool_size=(3,3))) # maxpool with window size 3x3. Max pool will extract the most prominant features\n"," \n","model.add(Conv2D(64,(3,3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(3,3))) \n","\n","model.add(Flatten()) #always flatten before a dense layer\n","model.add(Dense(64, activation='relu'))\n","model.add(Dropout(0.3)) # to prevent overfitting\n","\n","model.add(Dense(64, activation='relu'))\n","model.add(Dropout(0.3))\n","\n","model.add(Dense(2,activation='softmax'))\n","\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","model.fit(x,y,epochs=3,validation_split=0.1) #validation split divides the data set into testing and traing data\n","\n","model.save('catsdogs.model')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Epoch 1/3\n","704/704 [==============================] - 37s 9ms/step - loss: 0.6441 - accuracy: 0.6177 - val_loss: 0.5549 - val_accuracy: 0.7157\n","Epoch 2/3\n","704/704 [==============================] - 6s 8ms/step - loss: 0.5338 - accuracy: 0.7365 - val_loss: 0.5105 - val_accuracy: 0.7549\n","Epoch 3/3\n","704/704 [==============================] - 6s 8ms/step - loss: 0.4795 - accuracy: 0.7729 - val_loss: 0.4729 - val_accuracy: 0.7829\n","INFO:tensorflow:Assets written to: catsdogs.model/assets\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m1n6K_Y98Ou7","executionInfo":{"status":"ok","timestamp":1624459257567,"user_tz":-330,"elapsed":40,"user":{"displayName":"Vibhav Kharangate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTxso7WxORgT2TMx-Jc5_pXjshGzLeb1R1aVGgHrU=s64","userId":"06804277127361149800"}}},"source":["from tensorflow.keras.models import load_model"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"BLKoXFAy8QCp","colab":{"base_uri":"https://localhost:8080/","height":231},"executionInfo":{"status":"error","timestamp":1624459258285,"user_tz":-330,"elapsed":756,"user":{"displayName":"Vibhav Kharangate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTxso7WxORgT2TMx-Jc5_pXjshGzLeb1R1aVGgHrU=s64","userId":"06804277127361149800"}},"outputId":"be24d281-4be4-475f-d0f7-4eecd5c83804"},"source":["img_array=cv2.imread('dog.jpg',cv2.IMREAD_GRAYSCALE)\n","img_array=cv2.resize(img_array,(70,70))\n","img_array=img_array.reshape(-1,70,70,1)\n","\n","#load the model\n","#model=load_model('models/catsdogs.model')\n","\n","prediction=model.predict([img_array])\n","\n","print(categories[numpy.argmax(prediction)])"],"execution_count":9,"outputs":[{"output_type":"error","ename":"error","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-b3dfd857d416>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dog.jpg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimg_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mimg_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#load the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/resize.cpp:3720: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"]}]}]}